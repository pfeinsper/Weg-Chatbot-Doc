{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introdu\u00e7\u00e3o","text":""},{"location":"#chatbot-rag-weg","title":"Chatbot RAG WEG","text":""},{"location":"#introducao-e-motivacao-do-projeto","title":"Introdu\u00e7\u00e3o e motiva\u00e7\u00e3o do projeto","text":"<p>A WEG \u00e9 uma multinacional brasileira de refer\u00eancia global em equipamentos eletroeletr\u00f4nicos, com presen\u00e7a em mais de quarenta pa\u00edses e um portf\u00f3lio amplo que vai de motores e sistemas de automa\u00e7\u00e3o a solu\u00e7\u00f5es digitais. Essa diversidade, somada \u00e0 heterogeneidade dos ambientes de uso, faz com que o suporte a ocorr\u00eancias dependa fortemente de especialistas internos, o que aumenta o tempo entre solicita\u00e7\u00e3o, diagn\u00f3stico e solu\u00e7\u00e3o.</p> <p>No ch\u00e3o de f\u00e1brica, a aus\u00eancia de esta\u00e7\u00f5es de trabalho dispon\u00edveis para consulta a manuais ou sistemas de suporte torna o processo ainda mais fragmentado. Surge, portanto, a necessidade de um canal de atendimento acess\u00edvel e escal\u00e1vel, capaz de reduzir a lat\u00eancia no diagn\u00f3stico e oferecer orienta\u00e7\u00e3o pr\u00e1tica de forma segura.</p> <p>O objetivo deste projeto \u00e9 desenvolver um assistente conversacional, que utiliza RAG (Retrieval-Augmented Generation) para consultar manuais e procedimentos t\u00e9cnicos, apoiar o troubleshooting e, quando necess\u00e1rio, realizar a triagem estruturada para encaminhamento ao especialista com o contexto consolidado.</p> <p>A solu\u00e7\u00e3o aumenta a efici\u00eancia do atendimento ao dar mais autonomia aos usu\u00e1rios e, ao mesmo tempo, otimiza o trabalho das equipes t\u00e9cnicas, que passam a focar nos casos cr\u00edticos e complexos. Comprovada sua efic\u00e1cia, a abordagem pode ser replicada em outros departamentos da empresa que enfrentam desafios operacionais semelhantes.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>API com deploy na AWS e com um front-end que simula o ambiente do Microsoft Teams.</li> <li>Recupera\u00e7\u00e3o de informa\u00e7\u00f5es via RAG, utilizando Azure OpenAI + ChromaDB.</li> <li>Suporte a PDFs e CSVs como fontes de dados.</li> <li>Fluxo de decis\u00e3o e refinamento de perguntas via LangGraph.</li> <li>Handoff autom\u00e1tico para suporte humano quando necess\u00e1rio via e-mail.</li> <li>Utiliza\u00e7\u00e3o do modelo gpt-oss-120b da Azure OpenAI.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>\u26a1\ufe0f Comece em minutos Instale as depend\u00eancias, configure suas credenciais no <code>.env</code> e rode o servidor local. Veja instru\u00e7\u00f5es detalhadas em Getting Started.</p>"},{"location":"#membros-do-grupo","title":"Membros do grupo","text":"<ul> <li>Henrique Badin</li> <li>Luca Caruso</li> <li>Eduardo Castanho</li> <li>Felipe Maia</li> </ul>"},{"location":"aws_deploy/","title":"Deployment","text":""},{"location":"aws_deploy/#deploy-na-aws-lightsail","title":"Deploy na AWS Lightsail","text":"<p>Este guia descreve o passo a passo necess\u00e1rio para replicar o deploy do projeto em uma inst\u00e2ncia AWS Lightsail, incluindo:</p> <ul> <li>Cria\u00e7\u00e3o da chave SSH para clonar reposit\u00f3rios privados  </li> <li>Instala\u00e7\u00e3o do Docker e Docker Compose  </li> <li>Instala\u00e7\u00e3o e configura\u00e7\u00e3o da AWS CLI  </li> <li>Integra\u00e7\u00e3o com AWS Secrets Manager para vari\u00e1veis de ambiente  </li> <li>Subida dos containers via Docker Compose  </li> <li>Script de deploy automatizado  </li> </ul>"},{"location":"aws_deploy/#1-criacao-da-instancia-aws-lightsail","title":"1. Cria\u00e7\u00e3o da Inst\u00e2ncia AWS Lightsail","text":"<p>Para hospedar o projeto em um ambiente simples e est\u00e1vel, utilizamos o AWS Lightsail. Siga os passos abaixo:</p>"},{"location":"aws_deploy/#1-acessar-o-lightsail","title":"1. Acessar o Lightsail","text":"<p>Acesse: https://lightsail.aws.amazon.com Clique em Create instance.</p>"},{"location":"aws_deploy/#2-configurar-a-instancia","title":"2. Configurar a inst\u00e2ncia","text":"<p>Selecione:</p> <ul> <li>Platform: Linux/Unix  </li> <li>Blueprint: OS Only \u2192 Ubuntu 22.04 LTS (ou 20.04)  </li> <li>Instance plan: escolha conforme a necessidade</li> <li>Instance name: algo como <code>weg-chat-prod</code> </li> </ul>"},{"location":"aws_deploy/#3-criar-a-instancia","title":"3. Criar a inst\u00e2ncia","text":"<p>Clique em Create Instance e aguarde o provisionamento.</p>"},{"location":"aws_deploy/#4-conectar-via-ssh","title":"4. Conectar via SSH","text":"<p>Via navegador: - Connect using SSH</p>"},{"location":"aws_deploy/#2-criacao-do-secret-no-aws-secrets-manager-asm","title":"2. Cria\u00e7\u00e3o do Secret no AWS Secrets Manager (ASM)","text":"<p>O ASM armazena as vari\u00e1veis de ambiente do container Docker de forma segura.</p>"},{"location":"aws_deploy/#1-acessar-o-secrets-manager","title":"1. Acessar o Secrets Manager","text":"<p>Acesse: https://console.aws.amazon.com/secretsmanager Clique em Store a new secret.</p>"},{"location":"aws_deploy/#2-selecionar-tipo","title":"2. Selecionar tipo","text":"<ul> <li>Secret type: Other type of secret  </li> <li>Clique em Switch to plain text e insira o conte\u00fado JSON:</li> </ul> <pre><code>{\n  \"OPENAI_ENDPOINT\": ,\n  \"OPENAI_MODEL_DEPLOYMENT_NAME\": ,\n  \"OPENAI_MODEL_NAME\":,\n  \"OPENAI_API_VERSION\": ,\n  \"SECRET_OPENAI_API_KEY\": ,\n  \"EMBEDDING_ENDPOINT\":,\n  \"EMBEDDING_MODEL_DEPLOYMENT_NAME\":,\n  \"EMBEDDING_MODEL_NAME\":,\n  \"EMBEDDING_API_VERSION\":,\n  \"SECRET_EMBEDDING_API_KEY\":,\n  \"LANGSMITH_TRACING\":,\n  \"LANGSMITH_ENDPOINT\":,\n  \"LANGSMITH_API_KEY\":,\n  \"LANGSMITH_PROJECT\":,\n  \"OPENAI_API_KEY\":,\n  \"SECRET_EMAIL_FROM\":,\n  \"SECRET_EMAIL_TO\":,\n  \"CREDENTIALS\":,\n  \"GMAIL_TOKEN\":\n\n}\n</code></pre>"},{"location":"aws_deploy/#3-nome-do-secret","title":"3. Nome do secret","text":"<p>Exemplos:</p> <ul> <li><code>weg-chat-env-prod</code> </li> <li><code>backend-env-vars</code> </li> </ul>"},{"location":"aws_deploy/#4-criar-o-secret","title":"4. Criar o secret","text":"<p>Clique em Next \u2192 Next \u2192 Store.</p>"},{"location":"aws_deploy/#criacao-do-usuario-iam-para-acesso-ao-asm","title":"Cria\u00e7\u00e3o do Usu\u00e1rio IAM para Acesso ao ASM","text":"<p>O usu\u00e1rio IAM ser\u00e1 usado pela AWS CLI na inst\u00e2ncia Lightsail.</p>"},{"location":"aws_deploy/#1-criar-usuario-iam","title":"1. Criar usu\u00e1rio IAM","text":"<p>Acesse: https://console.aws.amazon.com/iam Clique em:</p> <ul> <li>Users \u2192 Create User </li> <li>Nome: <code>lightsail-secrets-user</code> </li> <li>Tipo de acesso: Programmatic Access</li> </ul>"},{"location":"aws_deploy/#2-conceder-permissoes","title":"2. Conceder permiss\u00f5es","text":""},{"location":"aws_deploy/#politica-recomendada-minima-necessaria","title":"Pol\u00edtica recomendada (m\u00ednima necess\u00e1ria)","text":"<p>Crie uma pol\u00edtica chamada SecretsManagerReadOnlyCustom:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:DescribeSecret\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre> <p>Atribua essa pol\u00edtica ao usu\u00e1rio.</p>"},{"location":"aws_deploy/#3-obter-as-chaves-de-acesso","title":"3. Obter as chaves de acesso","text":"<p>Ao finalizar, a AWS exibir\u00e1:</p> <ul> <li>AWS_ACCESS_KEY_ID </li> <li>AWS_SECRET_ACCESS_KEY</li> </ul> <p>Baixe o arquivo <code>.csv</code>.</p>"},{"location":"aws_deploy/#4-configurar-na-instancia-lightsail","title":"4. Configurar na inst\u00e2ncia Lightsail","text":"<p>Na m\u00e1quina:</p> <pre><code>aws configure\n</code></pre> <p>Insira:</p> <ul> <li>Access Key ID  </li> <li>Secret Access Key  </li> <li>Region: <code>sa-east-1</code> </li> <li>Output format: <code>json</code></li> </ul> <p>Agora a inst\u00e2ncia tem acesso ao Secrets Manager.</p>"},{"location":"aws_deploy/#5-gerar-chave-ssh-na-instancia-lightsail","title":"5. Gerar chave SSH na inst\u00e2ncia Lightsail","text":"<p>Gere a chave SSH dentro da  inst\u00e2ncia Lightsail:</p> <pre><code>ssh-keygen -t ed25519 -C \"lightsail-deploy\"\n</code></pre> <p>Quando perguntado sobre senha deixe vazio e pressione Enter.</p> <p>Exiba a chave p\u00fablica:</p> <pre><code>cat ~/.ssh/id_ed25519.pub\n</code></pre> <p>Copie o conte\u00fado (uma \u00fanica linha).</p>"},{"location":"aws_deploy/#6-adicionar-a-chave-ssh-ao-github","title":"6. Adicionar a chave SSH ao GitHub","text":"<p>No GitHub:</p> <ol> <li>Acesse Settings</li> <li>V\u00e1 em SSH and GPG Keys</li> <li>Clique New SSH Key</li> <li>Nome: <code>Lightsail</code></li> <li>Cole a chave p\u00fablica</li> <li>Salve</li> </ol> <p>Teste a conex\u00e3o:</p> <pre><code>ssh -T git@github.com\n</code></pre> <p>Voc\u00ea deve ver:</p> <pre><code>Hi SEU_USUARIO! You've successfully authenticated...\n</code></pre>"},{"location":"aws_deploy/#7-clonar-o-repositorio-via-ssh","title":"7. Clonar o reposit\u00f3rio via SSH","text":"<pre><code>git clone git@github.com:SEU_USUARIO/SEU_REPO.git\ncd SEU_REPO\n</code></pre>"},{"location":"aws_deploy/#8-instalar-docker-e-docker-compose","title":"8.  Instalar Docker e Docker Compose","text":"<pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade -y\ncurl -fsSL https://get.docker.com | sudo sh\nsudo usermod -aG docker ubuntu\nnewgrp docker\nsudo apt-get install -y docker-compose-plugin\n</code></pre>"},{"location":"aws_deploy/#9-instalar-aws-cli","title":"9. Instalar AWS CLI","text":"<pre><code>curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nsudo apt-get install -y unzip\nunzip awscliv2.zip\nsudo ./aws/install\naws configure\n</code></pre> <p>Configure com o usu\u00e1rio IAM que tem acesso ao Secrets Manager.</p>"},{"location":"aws_deploy/#10-subir-containers-com-docker-compose","title":"10. Subir containers com Docker Compose","text":"<pre><code>docker-compose up -d --build\n</code></pre>"},{"location":"aws_deploy/#11-checklist-final","title":"11. Checklist final","text":"<ul> <li>Criar inst\u00e2ncia Lightsail  </li> <li>Criar chave SSH  </li> <li>Adicionar no GitHub  </li> <li>Clonar reposit\u00f3rio  </li> <li>Instalar Docker  </li> <li>Instalar AWS CLI  </li> <li>Configurar IAM   </li> <li>Subir containers  </li> </ul>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#exemplos-de-videos-clique-nas-thumbnails","title":"Exemplos de v\u00eddeos (clique nas thumbnails)","text":"<p> Explica\u00e7\u00e3o do projeto como um todo com testes    </p> <p> Apenas testes do bot em a\u00e7\u00e3o    </p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting Started","text":"<p>Bem-vindo ao Chatbot RAG WEG! \ud83d\ude80 Aqui voc\u00ea encontra tudo o que precisa para instalar, rodar e explorar o projeto.</p>"},{"location":"getting-started/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Python</li> <li>Conta na Microsoft 365 Developer</li> <li>Chaves do Azure OpenAI</li> <li>Conta na AWS com permiss\u00f5es para criar recursos no Lightsail e Secrets Manager</li> </ul> <ul> <li> <p>\u23e9 Implementation   Como implementar o bot depois de fazer as instala\u00e7\u00f5es b\u00e1sicas Implementation</p> </li> <li> <p>\ud83c\udd99 Deploy   Como foi feito o deploy do bot na AWS Deploy</p> </li> <li> <p>\ud83d\udca1Examples   Alguns casos de uso do nosso Bot que voc\u00ea pode utilizar para testar Examples</p> </li> <li> <p>\ud83d\udcda References   Trabalhos Relacionados, Inspira\u00e7\u00f5es e Refer\u00eancias de Documenta\u00e7\u00e3o References</p> </li> </ul> <p>Caso tenha qualquer d\u00favida, pode entrar em contato com qualquer membro do grupo! Al\u00e9m disso, pode ver nosso processo de desenvolvimento com mais detalhes no reposit\u00f3rio do projeto e no Notion compartilhado da equipe:</p> <p>Notion</p>"},{"location":"implementation/","title":"Implementation","text":""},{"location":"implementation/#implementacao-and-architectural-details","title":"Implementa\u00e7\u00e3o and Architectural Details","text":"<p>O chatbot foi implementado utilizando a biblioteca LangGraph para orquestrar o fluxo de decis\u00e3o e refinamento das perguntas, garantindo que o bot formule perguntas de alto valor sempre que necess\u00e1rio, consiga responder perguntas de acordo com manuais t\u00e9cnicos e um FAQ da WEG quando julgar possuir capacidade para tal (confian\u00e7a acima de 0,9) e realize o handoff autom\u00e1tico para suporte humano quando necess\u00e1rio.</p>"},{"location":"implementation/#como-rodar","title":"Como rodar","text":"<p>No terminal, dentro da pasta <code>chatbot-local</code>, rode:</p> <pre><code>uvicorn app.main:app --reload --host\n</code></pre> <p>Ou se preferir (Recomendamos), pode subir um container Docker:</p> <pre><code>docker build -t weg-chatbot .\ndocker run -p 8000:8000 weg-chatbot\n</code></pre>"},{"location":"implementation/#arquitetura-da-solucao","title":"Arquitetura da Solu\u00e7\u00e3o","text":"<p>Diante do problema inicial trazido pela WEG, foi proposto um diagrama arquitetural, no qual o fluxo foi estruturado para comportar uma solu\u00e7\u00e3o enxuta, direta e ajustada \u00e0s necessidades do cliente.</p> <p> </p> <p>Figura 1 \u2013 Arquitetura v1</p> <p>Com essa arquitetura, chegou-se \u00e0 vers\u00e3o v1 que se introduz um grafo operacional governado por um n\u00f3 Decisor, respons\u00e1vel por controlar o uso do RAG, contabilizar tentativas (T) e definir desvios de fluxo. Em paralelo, os n\u00f3s Question Refiner, Topic Checker e Analyzer trabalham em conjunto para maximizar a recupera\u00e7\u00e3o correta de informa\u00e7\u00f5es e mensurar a confian\u00e7a das respostas.</p> <p>Quando a confian\u00e7a calculada fica abaixo de um limiar (threshold) de 90%, o m\u00f3dulo Whats Missing \u00e9 ativado e formula uma pergunta estrat\u00e9gica ao usu\u00e1rio para suprir lacunas informacionais. Caso o ciclo persista sem resolu\u00e7\u00e3o ap\u00f3s v\u00e1rias intera\u00e7\u00f5es, o n\u00f3 Summarizer compila um relat\u00f3rio estruturado em Markdown para handoff humano.</p>"},{"location":"implementation/#detalhes-de-cada-um-dos-modulos-necessarios-para-a-implementacao-dessa-arquitetura","title":"Detalhes de cada um dos m\u00f3dulos necess\u00e1rios para a implementa\u00e7\u00e3o dessa arquitetura","text":""},{"location":"implementation/#chatbot-graph","title":"Chatbot Graph","text":"<p>Este m\u00f3dulo implementa um fluxo conversacional com LangGraph, integrando Azure OpenAI, Chroma (RAG) e ferramentas para recupera\u00e7\u00e3o de contexto e controle de estado.</p>"},{"location":"implementation/#visao-geral","title":"Vis\u00e3o Geral","text":"<ul> <li>Modelo</li> <li>Vector Store: Chroma (<code>example_collection</code>) com <code>retriever(k=5)</code>.</li> <li>Mem\u00f3ria/Checkpoint: <code>InMemorySaver</code> com <code>thread_id=\"1\"</code>.</li> <li>Controle de handoff: <code>T</code> e <code>STOP_TRYS</code> limitam tentativas antes do handoff.</li> </ul>"},{"location":"implementation/#ferramentas","title":"Ferramentas","text":"<ul> <li><code>retrieve_documents(query)</code>: busca trechos relevantes no Chroma e retorna texto limpo.</li> <li><code>rewind_state(query)</code>: retrocede o estado para um checkpoint com <code>len(messages)==N</code>.</li> </ul>"},{"location":"implementation/#prompts-do-sistema-principais","title":"Prompts do Sistema (principais)","text":"<ul> <li>Decisor: agente humano/emp\u00e1tico; chama RAG se tema WEG for detectado.</li> <li>QuestionRefiner: reescreve a pergunta (1\u20132 frases) para melhorar a recupera\u00e7\u00e3o.</li> <li>RAG: n\u00e3o responde ao usu\u00e1rio; organiza JSON com t\u00f3picos e chunks verbatim.</li> <li>WhatsMissing: pergunta somente o que falta para atingir confian\u00e7a \u2265 0,90.</li> <li>Summarizer: encerra com handoff humano e gera relat\u00f3rio em Markdown.</li> </ul>"},{"location":"implementation/#helpers-resumo","title":"Helpers (resumo)","text":"<ul> <li><code>summarize_conversation(messages, k)</code>: resume \u00faltimas intera\u00e7\u00f5es e compacta hist\u00f3rico.</li> <li><code>history_retriever(messages)</code>: concatena conte\u00fados em texto \u00fanico.</li> <li><code>question_refiner(question, history)</code>: aplica o prompt de refinamento.</li> <li><code>last_human_question / last_rag_json / last_retrieve_context</code>: utilidades de contexto.</li> <li><code>last_confidence_and_reason</code>: extrai <code>{confidence, justificativa}</code> do <code>conf_analyzer</code>.</li> </ul>"},{"location":"implementation/#nos-do-grafo","title":"N\u00f3s do Grafo","text":"<ul> <li><code>decisor</code> \u2192 decide entre tool_call (RAG) ou resposta direta.</li> <li><code>question_refiner</code> \u2192 ajusta query antes da busca.</li> <li><code>topic_checker</code> \u2192 executa tools, organiza <code>CONTEXT</code> e chama RAG.</li> <li><code>analyzer</code> \u2192 estima confian\u00e7a (0\u20131); com \u2265 0,90 pode responder direto.</li> <li><code>whats_missing</code> \u2192 coleta dados faltantes quando confian\u00e7a &lt; 0,90.</li> <li><code>summarizer</code> \u2192 handoff humano + relat\u00f3rio estruturado.</li> </ul>"},{"location":"implementation/#regras-de-encaminhamento","title":"Regras de Encaminhamento","text":"<ul> <li><code>decisor</code>:</li> <li>Sem tool_call \u2192 END (resposta direta).</li> <li>Com tool_call \u2192 <code>question_refiner</code>.</li> <li>T atingiu STOP_TRYS \u2192 <code>summarizer</code>.</li> <li><code>analyzer</code>:</li> <li><code>confidence \u2265 0,90</code> e <code>T &lt; STOP_TRYS</code> \u2192 END (resposta final).</li> <li>Caso contr\u00e1rio \u2192 <code>whats_missing</code> \u2192 END.</li> </ul>"},{"location":"implementation/#execucao-cli","title":"Execu\u00e7\u00e3o (CLI)","text":"<ul> <li><code>stream_graph_updates(user_input)</code>: imprime eventos (confian\u00e7a, resposta final, follow-up, handoff).</li> <li>Loop interativo <code>while True</code>: l\u00ea entrada, processa e exibe sa\u00eddas do grafo.</li> </ul>"},{"location":"implementation/#populate-database","title":"Populate Database","text":"<p>Este m\u00f3dulo \u00e9 respons\u00e1vel por carregar e indexar documentos no Vector Store, com suporte a arquivos PDF e CSV.</p>"},{"location":"implementation/#pdfs","title":"PDFs:","text":"<ul> <li> <p>Os documentos em PDF s\u00e3o fragmentados em chunks por meio de um text splitter, respeitando tamanho m\u00e1ximo e sobreposi\u00e7\u00e3o configurados.</p> </li> <li> <p>Cada chunk recebe um ID \u00fanico no formato:</p> </li> </ul> <pre><code>source:page:chunk_index\n</code></pre>"},{"location":"implementation/#csvs","title":"CSVs:","text":"<ul> <li> <p>Os arquivos CSV s\u00e3o lidos linha a linha, utilizando ; como delimitador de colunas.</p> </li> <li> <p>Diferente dos PDFs, os CSVs n\u00e3o s\u00e3o fragmentados.</p> </li> <li> <p>Cada linha recebe um ID fixo no formato:</p> </li> </ul> <pre><code>source:row:0\n</code></pre>"},{"location":"implementation/#indexacao-e-persistencia","title":"Indexa\u00e7\u00e3o e Persist\u00eancia","text":""},{"location":"implementation/#apos-o-processamento","title":"Ap\u00f3s o processamento:","text":"<ol> <li> <p>Os documentos (chunks de PDFs e linhas de CSVs) s\u00e3o reunidos.</p> </li> <li> <p>O sistema verifica se j\u00e1 existem documentos no Chroma Vector Store.</p> </li> <li> <p>Apenas documentos ainda n\u00e3o indexados s\u00e3o adicionados, evitando duplicidade.</p> </li> <li> <p>Quando novos documentos s\u00e3o identificados, eles s\u00e3o adicionados e persistidos na base.</p> </li> </ol> <p>Esse processo garante que o armazenamento vetorial esteja sempre atualizado, incorporando novos conte\u00fados sem recriar ou duplicar registros j\u00e1 existentes.</p>"},{"location":"references/","title":"References","text":""},{"location":"references/#references","title":"References","text":"<ul> <li>MRD-RAG: MRD-RAG</li> <li>Documenta\u00e7\u00e3o do Teams: Build a RAG bot in Teams</li> <li>LangChain &amp; LangGraph:<ol> <li>LangChain</li> <li>LangGraph</li> </ol> </li> </ul>"}]}